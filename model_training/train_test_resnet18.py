import argparse
from pathlib import Path

import torch
import torchvision
from colorama import Fore, Style
from torch import nn, optim

from helper import data_setup, engine, utils

parser = argparse.ArgumentParser(
    description="Script to train and test a model.",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)

# Add the type of images the APK files should be converted to
parser.add_argument(
    "-t",
    "--type",
    choices=["RGB", "BW"],
    required=True,
    help="Type of images.",
)

# Add the padding type to use
parser.add_argument(
    "-p",
    "--padding_type",
    choices=["random", "black", "white"],
    required=True,
    help="Type of padding to used to create the images.",
)

parser.add_argument("-e", "--epochs", type=int, default=5, help="Number of epochs.")

args = parser.parse_args()

# Set the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Setup directories
image_path = Path("_images")
train_dir = image_path / "train"
test_dir = image_path / "test"

# Setup pretrained weights
weights = torchvision.models.ResNet18_Weights.DEFAULT

# Normalization and transformation based on the ImageNet dataset training images (https://pytorch.org/vision/stable/models.html)
automatic_transforms = weights.transforms()

# Create data loaders
train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(
    train_dir=train_dir,
    test_dir=test_dir,
    transform=automatic_transforms,
    batch_size=32,
)

# Create a pretrained model freezing the base layers
model = torchvision.models.resnet18(weights=weights).to(device)

print(
    f"{Fore.GREEN}[INFO]{Style.RESET_ALL} automatic_transforms: ", automatic_transforms
)
print(f"{Fore.GREEN}[INFO]{Style.RESET_ALL} train_dataloader: ", train_dataloader)
print(f"{Fore.GREEN}[INFO]{Style.RESET_ALL} test_dataloader: ", test_dataloader)
print(
    f"{Fore.GREEN}[INFO]{Style.RESET_ALL} Number of classes: {len(class_names)}, class names: {class_names}"
)


# Freeze the base layers
for param in model.parameters():
    param.requires_grad = False

# Change the fully connected layer structure to match ResNet-18's output (512 for ResNet-18 vs. 2048 for ResNet-50)
model.fc = torch.nn.Sequential(
    nn.Linear(512, 500),
    nn.ReLU(
        inplace=True
    ),  # Changed from Mish to ReLU; you can revert this if you have a specific reason to use Mish.
    nn.Linear(500, 2),
).to(device)

# Define loss and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters())

engine.train(
    model=model,
    train_dataloader=train_dataloader,
    test_dataloader=test_dataloader,
    optimizer=optimizer,
    loss_fn=loss_fn,
    epochs=args.epochs,
    device=device,
    writer=engine.create_writer(
        experiment_name="test",
        model_name=f"resnet18_{args.type}_{args.padding_type}",
        extra=f"{args.epochs}_epochs",
    ),
)

# Save the model to file so we can get back the best performing model
save_filepath = (
    f"_models/resnet18_{args.type}_{args.padding_type}_{args.epochs}_epochs.pth"
)
utils.save_model(model=model, target_dir="model_training", model_name=save_filepath)
