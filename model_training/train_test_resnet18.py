import os
import numpy as np
from PIL import Image
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import torch
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torchvision.models as models
import pandas as pd
import seaborn as sns
from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score


def process_image(filepath, image_shape):
    image = Image.open(filepath)
    image_resized = image.resize(image_shape)  # Resize the image
    image_array = np.array(image_resized)
    return image_array


def print_confusion_matrix(
    confusion_matrix, class_names, output_file, figsize=(10, 7), fontsize=20
):
    df_cm = pd.DataFrame(
        confusion_matrix,
        index=class_names,
        columns=class_names,
    )
    fig = plt.figure(figsize=figsize)
    heatmap = sns.heatmap(
        df_cm, annot=True, fmt="d", cmap="Blues", annot_kws={"size": 20}
    )
    heatmap.yaxis.set_ticklabels(
        heatmap.yaxis.get_ticklabels(), rotation=0, ha="right", fontsize=fontsize
    )
    heatmap.xaxis.set_ticklabels(
        heatmap.xaxis.get_ticklabels(), rotation=0, ha="right", fontsize=fontsize
    )
    plt.ylabel("True label")
    plt.xlabel("Predicted label")
    plt.savefig(output_file, bbox_inches="tight")
    plt.close(fig)


def load_images(goodware_folder, malware_folder, image_shape=(256, 256)):
    image_list = []
    labels = []

    # Load Goodware images
    for filename in tqdm(os.listdir(goodware_folder), desc="Loading Goodware Images"):
        if filename.endswith(".png") or filename.endswith(".jpg"):
            filepath = os.path.join(goodware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            labels.append(0)  # 0 for Goodware

    # Load Malware images
    for filename in tqdm(os.listdir(malware_folder), desc="Loading Malware Images"):
        if filename.endswith(".png") or filename.endswith(".jpg"):
            filepath = os.path.join(malware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            if "MALWARE" in filename:
                labels.append(1)  # 1 for Malware
            else:
                labels.append(0)  # 0 for Goodware

    images = np.array(image_list)
    labels = np.array(labels)

    return images, labels


# Loading images
goodware_folder = "_dataset/Goodware_obf"
malware_folder = "_dataset/Malware_obf"
x, y = load_images(goodware_folder, malware_folder)

# Splitting into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(
    x, y, test_size=0.20, random_state=42, shuffle=True
)

# Plot and save a training image
plt.imshow(x_train[96])
plt.savefig("training_image.png")

# PyTorch device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Normalization and transformation
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])


# Define dataset class
class MyDataset(Dataset):
    def __init__(self, x, y, transform=None):
        self.x = x
        self.y = y
        self.transform = transform

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        img = Image.fromarray(self.x[index])
        label = self.y[index]

        if self.transform:
            img = self.transform(img)

        return img, label


transform = transforms.Compose(
    [transforms.Resize((224, 224)), transforms.ToTensor(), normalize]
)

# Training and validation
dataset = MyDataset(x_train, y_train, transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# Change the model to ResNet-18
model = models.resnet18(pretrained=True).to(device)

for param in model.parameters():
    param.requires_grad = False

# Change the fully connected layer structure to match ResNet-18's output (512 for ResNet-18 vs. 2048 for ResNet-50)
model.fc = nn.Sequential(
    nn.Linear(512, 500),
    nn.ReLU(
        inplace=True
    ),  # Changed from Mish to ReLU; you can revert this if you have a specific reason to use Mish.
    nn.Linear(500, 2),
).to(device)


criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters())


num_epochs = 60
total_batches = len(dataloader)
for epoch in range(num_epochs):
    running_loss = 0.0
    for i, data in enumerate(dataloader, 0):
        if i >= total_batches:
            break

        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.type(torch.LongTensor)
        labels = labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 100 == 99:
            print(
                f"Epoch {epoch+1}, batch {i+1}/{total_batches}: loss={running_loss/100:.4f}"
            )
            running_loss = 0.0

    # print(f'Batch {i+1}/{total_batches}: inputs={inputs.shape}, labels={labels.shape}')

print("Finished training")

# Save the trained model
torch.save(model, "trained_model_rgb_resnet_18.pth")

# Validation
val_dataset = MyDataset(x_val, y_val, transform)
val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)
model.eval()

# Variables for accuracy and loss
total_correct = 0
total_loss = 0.0
total_samples = 0
all_labels = []
all_predicted = []

# Validation loop
with torch.no_grad():
    for i, data in enumerate(val_dataloader, 0):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.type(torch.LongTensor)
        labels = labels.to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        all_labels.extend(labels.cpu().numpy())
        all_predicted.extend(predicted.cpu().numpy())
        total_samples += labels.size(0)
        total_correct += (predicted == labels).sum().item()

print(f"Validation accuracy: {total_correct/total_samples:.4f}")

# Compute recall, precision, and F1 score
recall = recall_score(all_labels, all_predicted)
precision = precision_score(all_labels, all_predicted)
f1 = f1_score(all_labels, all_predicted)

print(f"Recall: {recall:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1 Score: {f1:.2f}")

# Calculate confusion matrix
cm = confusion_matrix(all_labels, all_predicted)

# Define class names (in this case, 0 for Goodware, 1 for Malware)
class_names = ["Goodware", "Malware"]

# Output file path for saving the confusion matrix plot
output_file = "confusion_matrix.png"

# Call the function to print the confusion matrix
print_confusion_matrix(cm, class_names, output_file)
