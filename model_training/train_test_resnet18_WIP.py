import argparse
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from torch import nn, optim
from torch.utils.data import DataLoader, Dataset
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

# Make the script interactive through the CLI
parser = argparse.ArgumentParser(
    description="Script to train and test a model.",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)

# Add the type of images the APK files should be converted to
parser.add_argument(
    "-t",
    "--type",
    choices=["RGB", "BW"],
    required=True,
    help="Type of images.",
)

# Add the padding type to use
parser.add_argument(
    "-p",
    "--padding_type",
    choices=["random", "black", "white"],
    required=True,
    help="Type of padding to used to create the images.",
)

# Add location to the root location of the images to be saved at
parser.add_argument(
    "-i",
    "--images",
    nargs="?",
    default="_images",
    help="Provide the root path of the images to be saved at. It is a path relative to your current working directory.",
)

# Add location of where the model is saved
parser.add_argument(
    "-m",
    "--model_location",
    nargs="?",
    default="model_training/_models",
    help="Provide the root path of the models location. It is a path. It is a path relative to your current working directory.",
)


# Add choice on which type of device to run the script
parser.add_argument(
    "-r", "--run_on", choices=["local", "cluster"], nargs="?", default="local"
)

args = parser.parse_args()


def process_image(filepath, image_shape):
    image = Image.open(filepath)
    image_resized = image.resize(image_shape)  # Resize the image
    image_array = np.array(image_resized)
    return image_array


def print_confusion_matrix(
    confusion_matrix, class_names, output_file, figsize=(10, 7), fontsize=20
):
    df_cm = pd.DataFrame(
        confusion_matrix,
        index=class_names,
        columns=class_names,
    )
    fig = plt.figure(figsize=figsize)
    heatmap = sns.heatmap(
        df_cm, annot=True, fmt="d", cmap="Blues", annot_kws={"size": 20}
    )
    heatmap.yaxis.set_ticklabels(
        heatmap.yaxis.get_ticklabels(), rotation=0, ha="right", fontsize=fontsize
    )
    heatmap.xaxis.set_ticklabels(
        heatmap.xaxis.get_ticklabels(), rotation=0, ha="right", fontsize=fontsize
    )
    plt.ylabel("True label")
    plt.xlabel("Predicted label")
    plt.savefig(output_file, bbox_inches="tight")
    plt.close(fig)


def load_images(goodware_folder, malware_folder, image_shape=(256, 256)):
    image_list = []
    labels = []

    # Load Goodware images
    for filename in tqdm(os.listdir(goodware_folder), desc="Loading Goodware Images"):
        if filename.endswith(".png") or filename.endswith(".jpg"):
            filepath = os.path.join(goodware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            labels.append(0)  # 0 for Goodware

    # Load Malware images
    for filename in tqdm(os.listdir(malware_folder), desc="Loading Malware Images"):
        if filename.endswith(".png") or filename.endswith(".jpg"):
            filepath = os.path.join(malware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            if "MALWARE" in filename:
                labels.append(1)  # 1 for Malware
            else:
                labels.append(0)  # 0 for Goodware

    images = np.array(image_list)
    labels = np.array(labels)

    return images, labels


# Loading images
match args.run_on:
    case "local":
        goodware_folder = "_images/Subset_goodware_obf"
        malware_folder = "_images/Subset_malware_obf"
    case "cluster":
        goodware_folder = (
            args.images
            + "/Goodware_obf"
            + "_"
            + args.type
            + "_"
            + args.padding_type
            + "_padding"
        )
        malware_folder = (
            args.images
            + "/Malware_obf"
            + "_"
            + args.type
            + "_"
            + args.padding_type
            + "_padding"
        )

x, y = load_images(goodware_folder, malware_folder)

# Splitting into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(
    x, y, test_size=0.20, random_state=42, shuffle=True
)

# Plot and save a training image
# plt.imshow(x_train[96])
# plt.savefig("training_image.png")

# PyTorch device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Normalization and transformation
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])


# Define dataset class
class MyDataset(Dataset):
    def __init__(self, x, y, transform=None):
        self.x = x
        self.y = y
        self.transform = transform

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        img = Image.fromarray(self.x[index])
        label = self.y[index]

        if self.transform:
            img = self.transform(img)

        return img, label


transform = transforms.Compose(
    [transforms.Resize((512, 512)), transforms.ToTensor(), normalize]
)

# Training dataset
dataset = MyDataset(x_train, y_train, transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# Validation dataset
val_dataset = MyDataset(x_val, y_val, transform)
val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)


# Change the model to ResNet-18
model = models.resnet18(pretrained=True).to(device)

for param in model.parameters():
    param.requires_grad = False

# Change the fully connected layer structure to match ResNet-18's output (512 for ResNet-18 vs. 2048 for ResNet-50)
model.fc = nn.Sequential(
    nn.Linear(512, 500),
    nn.ReLU(
        inplace=True
    ),  # Changed from Mish to ReLU; you can revert this if you have a specific reason to use Mish.
    nn.Linear(500, 2),
).to(device)


criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters())

# TensorBoard setup
os.makedirs(f"{args.model_location}/runs", exist_ok=True)
writer = SummaryWriter(f"{args.model_location}/runs/")

# Training and Validation Loop
num_epochs = 60
total_batches = len(dataloader)
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    epoch_correct = 0
    epoch_samples = 0
    for i, data in enumerate(dataloader, 0):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.type(torch.LongTensor)
        labels = labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        epoch_correct += (predicted == labels).sum().item()
        epoch_samples += labels.size(0)

    # Log training metrics
    train_loss = running_loss / total_batches
    train_accuracy = epoch_correct / epoch_samples
    writer.add_scalar("Training Loss", train_loss, epoch)
    writer.add_scalar("Training Accuracy", train_accuracy, epoch)

    # Validation phase
    model.eval()
    val_running_loss = 0.0
    val_correct = 0
    val_total = 0
    val_all_labels = []
    val_all_predictions = []

    with torch.no_grad():
        for inputs, labels in val_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            val_running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            val_correct += (predicted == labels).sum().item()
            val_total += labels.size(0)

            val_all_labels.extend(labels.cpu().numpy())
            val_all_predictions.extend(predicted.cpu().numpy())

    # Log validation metrics
    val_loss = val_running_loss / len(val_dataloader)
    val_accuracy = val_correct / val_total
    writer.add_scalar("Validation Loss", val_loss, epoch)
    writer.add_scalar("Validation Accuracy", val_accuracy, epoch)

    # Calculate and log additional metrics
    recall = recall_score(val_all_labels, val_all_predictions)
    precision = precision_score(val_all_labels, val_all_predictions)
    f1 = f1_score(val_all_labels, val_all_predictions)

    writer.add_scalar("Recall", recall, epoch)
    writer.add_scalar("Precision", precision, epoch)
    writer.add_scalar("F1 Score", f1, epoch)

# Save the model and close the TensorBoard writer
torch.save(model, f"{args.model_location}/model.pth")
writer.close()

# Compute confusion matrix
cm = confusion_matrix(val_all_labels, val_all_predictions)

# Define class names
class_names = ["Goodware", "Malware"]

# Output file path for saving the confusion matrix plot
output_file = f"{args.model_location}/confusion_matrix_{args.type}_{args.padding_type}_padding.png"

# Call the function to print the confusion matrix
print_confusion_matrix(cm, class_names, output_file)
