import argparse
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from torch import nn, optim
from torch.utils.data import DataLoader, Dataset

# from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

# Make the script interactive through the CLI
parser = argparse.ArgumentParser(
    description="Script to train and test a model.",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)

# Add the type of images the APK files should be converted to
parser.add_argument(
    "-t",
    "--type",
    choices=["RGB", "BW"],
    required=True,
    help="Type of images.",
)

# Add the padding type to use
parser.add_argument(
    "-p",
    "--padding_type",
    choices=["random", "black", "white"],
    required=True,
    help="Type of padding to used to create the images.",
)

# Add location to the root location of the images to be saved at
parser.add_argument(
    "-i",
    "--images",
    nargs="?",
    default="_images",
    help="Provide the root path of the images to be saved at. It is a path relative to your current working directory.",
)

# Add location of where the model is saved
parser.add_argument(
    "-m",
    "--model_location",
    nargs="?",
    default="model_training/_models",
    help="Provide the root path of the models location. It is a path. It is a path relative to your current working directory.",
)


# Add choice on which type of device to run the script
parser.add_argument(
    "-r", "--run_on", choices=["local", "cluster"], nargs="?", default="cluster"
)

args = parser.parse_args()


def process_image(filepath, image_shape):
    image = Image.open(filepath)
    image_resized = image.resize(image_shape)  # Resize the image
    image_array = np.array(image_resized)
    return image_array


def print_confusion_matrix(
    confusion_matrix, class_names, output_file, figsize=(10, 7), fontsize=20
):
    df_cm = pd.DataFrame(
        confusion_matrix,
        index=class_names,
        columns=class_names,
    )
    fig = plt.figure(figsize=figsize)
    heatmap = sns.heatmap(
        df_cm, annot=True, fmt="d", cmap="Blues", annot_kws={"size": 20}
    )
    heatmap.yaxis.set_ticklabels(
        heatmap.yaxis.get_ticklabels(), rotation=0, ha="right", fontsize=fontsize
    )
    heatmap.xaxis.set_ticklabels(
        heatmap.xaxis.get_ticklabels(), rotation=0, ha="right", fontsize=fontsize
    )
    plt.ylabel("True label")
    plt.xlabel("Predicted label")
    plt.savefig(output_file, bbox_inches="tight")
    plt.close(fig)


def load_images(goodware_folder, malware_folder, image_shape=(256, 256)):
    image_list = []
    labels = []

    # Load Goodware images
    for filename in tqdm(os.listdir(goodware_folder), desc="Loading Goodware Images"):
        if filename.endswith(".png") or filename.endswith(".jpg"):
            filepath = os.path.join(goodware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            labels.append(0)  # 0 for Goodware

    # Load Malware images
    for filename in tqdm(os.listdir(malware_folder), desc="Loading Malware Images"):
        if filename.endswith(".png") or filename.endswith(".jpg"):
            filepath = os.path.join(malware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            if "MALWARE" in filename:
                labels.append(1)  # 1 for Malware
            else:
                labels.append(0)  # 0 for Goodware

    images = np.array(image_list)
    labels = np.array(labels)

    return images, labels


# Loading images
match args.run_on:
    case "local":
        goodware_folder = (
            args.images
            + "/Subset_goodware_obf"
            + f"_{args.type}_{args.padding_type}_padding"
        )
        malware_folder = (
            args.images
            + "/Subset_malware_obf"
            + f"_{args.type}_{args.padding_type}_padding"
        )
    case "cluster":
        goodware_folder = (
            args.images + "/Goodware_obf" + f"_{args.type}_{args.padding_type}_padding"
        )
        malware_folder = (
            args.images + "/Malware_obf" + f"_{args.type}_{args.padding_type}_padding"
        )

x, y = load_images(goodware_folder, malware_folder)

# Splitting into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(
    x, y, test_size=0.20, random_state=42, shuffle=True
)

# Plot and save a training image
# plt.imshow(x_train[96])
# plt.savefig("training_image.png")

# PyTorch device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Normalization and transformation
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])


# Define dataset class
class MyDataset(Dataset):
    def __init__(self, x, y, transform=None):
        self.x = x
        self.y = y
        self.transform = transform

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        img = Image.fromarray(self.x[index])
        label = self.y[index]

        if self.transform:
            img = self.transform(img)

        return img, label


transform = transforms.Compose(
    [transforms.Resize((512, 512)), transforms.ToTensor(), normalize]
)

# Training and validation
dataset = MyDataset(x_train, y_train, transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)


# Create VGG16 model
class VGG16(nn.Module):
    def __init__(self, num_classes=2):
        super(VGG16, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.layer3 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
        )
        self.layer4 = nn.Sequential(
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.layer5 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
        )
        self.layer6 = nn.Sequential(
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
        )
        self.layer7 = nn.Sequential(
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.layer8 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
        )
        self.layer9 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
        )
        self.layer10 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.layer11 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
        )
        self.layer12 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
        )
        self.layer13 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(16 * 16 * 512, 4096),  # To keep input images of 512x512
            # nn.Linear(7*7*512, 4096),
            nn.ReLU(),
        )
        self.fc1 = nn.Sequential(nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU())
        self.fc2 = nn.Sequential(nn.Linear(4096, num_classes))

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.layer5(out)
        out = self.layer6(out)
        out = self.layer7(out)
        out = self.layer8(out)
        out = self.layer9(out)
        out = self.layer10(out)
        out = self.layer11(out)
        out = self.layer12(out)
        out = self.layer13(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        out = self.fc1(out)
        out = self.fc2(out)
        return out


model = VGG16().to(device)

# model = models.resnet18(pretrained=True).to(device)

for param in model.parameters():
    param.requires_grad = True

# Change the fully connected layer structure to match ResNet-18's output (512 for ResNet-18 vs. 2048 for ResNet-50)
# model.fc = nn.Sequential(
# nn.Linear(512, 500),
# nn.ReLU(
# inplace=True
# ),  # Changed from Mish to ReLU; you can revert this if you have a specific reason to use Mish.
# nn.Linear(500, 2),
# ).to(device)


criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters())

# TODO: Create a SummaryWriter object to write TensorBoard events
# runs_dir = os.path.join(args.model_location, "runs")
# os.makedirs(runs_dir, exist_ok=True)
# writer = SummaryWriter(
#     os.path.join(runs_dir, f"resnet_18_{args.type}_{args.padding_type}_padding_run")
# )

num_epochs = 60
total_batches = len(dataloader)
for epoch in range(num_epochs):
    running_loss = 0.0
    for i, data in tqdm(
        enumerate(dataloader, 0),
        total=total_batches,
        desc=f"Epoch {epoch+1}/{num_epochs}",
    ):
        if i >= total_batches:
            break

        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.type(torch.LongTensor)
        labels = labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 100 == 99:
            print(
                f"Epoch {epoch+1}, batch {i+1}/{total_batches}: loss={running_loss/100:.4f}"
            )
            running_loss = 0.0

    # print(f'Batch {i+1}/{total_batches}: inputs={inputs.shape}, labels={labels.shape}')

print("Finished training")

# Save the trained model
models_dir = os.path.join("model_training", "_models")
os.makedirs(models_dir, exist_ok=True)

model_path = os.path.join(
    models_dir, f"trained_model_vgg16_{args.type}_{args.padding_type}_padding.pth"
)

torch.save(model, model_path)

# Validation
val_dataset = MyDataset(x_val, y_val, transform)
val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)
model.eval()

# Variables for accuracy and loss
total_correct = 0
total_loss = 0.0
total_samples = 0
all_labels = []
all_predicted = []

# Validation loop
with torch.no_grad():
    for i, data in tqdm(
        enumerate(val_dataloader, 0), total=len(val_dataloader), desc="Validating"
    ):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.type(torch.LongTensor)
        labels = labels.to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        total_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        all_labels.extend(labels.cpu().numpy())
        all_predicted.extend(predicted.cpu().numpy())
        total_samples += labels.size(0)
        total_correct += (predicted == labels).sum().item()

print(f"Validation accuracy: {total_correct/total_samples:.4f}")

# Compute recall, precision, and F1 score
recall = recall_score(all_labels, all_predicted)
precision = precision_score(all_labels, all_predicted)
f1 = f1_score(all_labels, all_predicted)

print(f"Recall: {recall:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1 Score: {f1:.2f}")

# Calculate confusion matrix
cm = confusion_matrix(all_labels, all_predicted)

# Define class names (in this case, 0 for Goodware, 1 for Malware)
class_names = ["Goodware", "Malware"]

# Output file path for saving the confusion matrix plot
output_file = f"{args.model_location}/confusion_matrix_{args.type}_{args.padding_type}_padding.png"

# Call the function to print the confusion matrix
print_confusion_matrix(cm, class_names, output_file)

# New code to append model performance to "performance.txt"
with open("performance.txt", "a") as f:
    f.write(f"Model: VGG16 - 512x512 input - square kernel\n")
    f.write(f"F1 Score: {f1:.2f}\n")
    f.write(f"Recall: {recall:.2f}\n")
    f.write(f"Precision: {precision:.2f}\n")
    f.write("\n")  # Add a newline for readability
