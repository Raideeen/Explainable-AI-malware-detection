"""Makes a prediction on a target image and plots the image with its prediction."""

# Import libraries 
import torch 
import argparse
import matplotlib.pyplot as plt 

from torchvision import io, transforms
# from going_modular import model_builder
import model_builder

# Setup device-agnostic code
device = "cuda" if torch.cuda.is_available else "cpu" 

parser = argparse.ArgumentParser(prog="Pizza/Steak/Sushi classifier", description="Program to classify photos of food in three classes (pizza/steak/sushi)")

parser.add_argument("--image", 
                    "-img",
                    type=str,
                    help="Path to the image. Should contains the extension.\nExample:\n\tdata/pizza_steak_sushi/test/sushi/175783.jpg")
parser.add_argument("--model_path",
                    "-m",
                    type=str,
                    help="Path to the model. Should contains the extension (.pt or .pth).\nExample:\n\tmodels/tinyvgg.pth",
                    default="models/05_going_modular_cell_mode_tinyvgg_model.pth")
parser.add_argument("--model_params",
                    "-params",
                    type=int,
                    help="Model parameters in the form of [color_channel, hidden_units, number_of_classes]",
                    nargs=3,
                    default=[3,10,3])
args = parser.parse_args()

# Setup variables 
IMAGE_PATH = args.image  
MODEL_PATH = args.model_path
MODEL_SHAPE = args.model_params

class_names = ["Pizza", "Steak", "Sushi"]

# Setup transform 
simple_transform = transforms.Compose([
    transforms.Resize(size=(64,64)),
    ])

# Load parameters from existing model 
model = model_builder.TinyVGG(input_shape=MODEL_SHAPE[0], hidden_units=MODEL_SHAPE[1], output_shape=MODEL_SHAPE[2])
model.load_state_dict(torch.load(f=MODEL_PATH))

# 1. Load in image and convert the tensor values to float32
target_image = io.read_image(str(IMAGE_PATH)).type(torch.float32)

# 2. Divide the image pixel values by 255 to get them between [0, 1]
target_image = target_image / 255. 

# 3. Transform image to fit model specification
target_image = simple_transform(target_image)

# 4. Make sure the model is on the target device
model.to(device)

# 5. Turn on model evaluation mode and inference mode
model.eval()
with torch.inference_mode():
    # Add an extra dimension to the image
    target_image = target_image.unsqueeze(dim=0)

    # Make a prediction on image with an extra dimension and send it to the target device
    target_image_pred = model(target_image.to(device))
    
# 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)
target_image_pred_probs = torch.softmax(target_image_pred, dim=1)

# 7. Convert prediction probabilities -> prediction labels
target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)

prediction = f"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}"

print(prediction)
    
