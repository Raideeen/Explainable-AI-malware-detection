""" Main module for testing optimizers """
# Load libraries and pick the CUDA device if available
import json
import os
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
#import torchvision
#import torchvision.transforms as transforms
from torch.utils.tensorboard import SummaryWriter
import torch.optim as optim
import matplotlib.pyplot as plt
#import numpy as np
import time
# Custom libraries
import torchvision.models as models
#from CustomOptimizer import *

from src.attack import FastGradientSignUntargeted
#from LinfPGDAttack import *
#import torchattacks


from loader import *
#from src.models import MODELS_MAP
from src.utils import *

import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1"
use_cuda = torch.cuda.is_available()
device = torch.device("cpu")

GOODWARE_FOLDER = '/home/hugodhugo/recherche/mini_dataset_images/goodware_obf'
MALWARE_FOLDER = '/home/hugodhugo/recherche/mini_dataset_images/malware_obf'

def test(model, loader, adv_test=False, use_pseudo_label=False, attack=None):
        # adv_test is False, return adv_acc as -1 

        total_acc = 0.0
        num = 0
        total_adv_acc = 0.0

        with torch.no_grad():
            for data, label in loader:
                data, label = tensor2cuda(data), tensor2cuda(label)

                output = model(data)

                pred = torch.max(output, dim=1)[1]
                te_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy(), 'sum')
                
                total_acc += te_acc
                num += output.shape[0]

                if adv_test:
                    # use predicted label as target label
                    with torch.enable_grad():
                        adv_data = attack.perturb(data, 
                                                       pred if use_pseudo_label else label, 
                                                       'mean', 
                                                       False)

                    adv_output = model(adv_data)

                    adv_pred = torch.max(adv_output, dim=1)[1]
                    adv_acc = evaluate(adv_pred.cpu().numpy(), label.cpu().numpy(), 'sum')
                    total_adv_acc += adv_acc
                else:
                    total_adv_acc = -num

        return total_acc / num , total_adv_acc / num

# Trains the network
def train(model,tr_loader,va_loader=None, adv_train=False, attack=None):
        

        opt = optimizer
        scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, 
                                                         milestones=[40000, 60000], 
                                                         gamma=0.1)
        _iter = 0

        begin_time = time.time()

        writer1 = SummaryWriter(config_dict['tb_path_train'])
        writer2 = SummaryWriter(config_dict['tb_path_test'])

        for epoch in range(1, config_dict['epochs']+1):
            for data, label in tr_loader:
                data, label = tensor2cuda(data), tensor2cuda(label)

                if adv_train:
                    # When training, the adversarial example is created from a random 
                    # close point to the original data point. If in evaluation mode, 
                    # just start from the original data point.
                    adv_data = attack.perturb(data, label, 'mean', True)
                    save_images(data[0], adv_data[0], _iter)

                    output = model(adv_data)
                else:
                    output = model(data, _eval=False)

                loss = F.cross_entropy(output, label)

                opt.zero_grad()
                loss.backward()
                opt.step()

                if _iter % config_dict['n_eval_step'] == 0:
                    t1 = time.time()

                    if adv_train:
                        with torch.no_grad():
                            stand_output = model(data)
                        pred = torch.max(stand_output, dim=1)[1]

                        # print(pred)
                        std_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy()) * 100

                        pred = torch.max(output, dim=1)[1]
                        # print(pred)
                        adv_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy()) * 100

                    else:
                        
                        adv_data = attack.perturb(data, label, 'mean', False)

                        with torch.no_grad():
                            adv_output = model(adv_data)
                        pred = torch.max(adv_output, dim=1)[1]
                        # print(label)
                        # print(pred)
                        adv_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy()) * 100

                        pred = torch.max(output, dim=1)[1]
                        # print(pred)
                        std_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy()) * 100

                    t2 = time.time()

                    logger.info(f'epoch: {epoch}, iter: {_iter}, lr={opt.param_groups[0]["lr"]}, '
                                f'spent {time.time()-begin_time:.2f} s, tr_loss: {loss.item():.3f}')

                    logger.info(f'standard acc: {std_acc:.3f}%, robustness acc: {adv_acc:.3f}%')
                    
                    writer1.add_scalar('Accuracy', std_acc, _iter)
   
                    writer1.add_scalar('Adversarial Accuracy', adv_acc, _iter)
                    # begin_time = time()

                    # if va_loader is not None:
                    #     va_acc, va_adv_acc = self.test(model, va_loader, True)
                    #     va_acc, va_adv_acc = va_acc * 100.0, va_adv_acc * 100.0

                    #     logger.info('\n' + '='*30 + ' evaluation ' + '='*30)
                    #     logger.info('test acc: %.3f %%, test adv acc: %.3f %%, spent: %.3f' % (
                    #         va_acc, va_adv_acc, time() - begin_time))
                    #     logger.info('='*28 + ' end of evaluation ' + '='*28 + '\n')

                    begin_time = time.time()

                

                _iter += 1
                # scheduler depends on training interation
                scheduler.step()

            if va_loader is not None:
                t1 = time.time()
                va_acc, va_adv_acc = test(model, va_loader, True, False, attack)
                va_acc, va_adv_acc = va_acc * 100.0, va_adv_acc * 100.0
                
                t2 = time.time()
                logger.info('\n'+'='*20 +f' evaluation at epoch: {epoch} iteration: {_iter} ' \
                    +'='*20)
                logger.info(f'test acc: {va_acc:.3f}%, test adv acc: {va_adv_acc:.3f}%, spent: {t2-t1:.3f} s')
                logger.info('='*28+' end of evaluation '+'='*28+'\n')
                
                writer2.add_scalar('Accuracy', va_acc, _iter)
   
                writer2.add_scalar('Adversarial Accuracy', va_adv_acc, _iter)

        writer2.close()
        writer1.close()

#H - Classic parse function, for now only takes the json and return the config_dict
#will later add other arguments for path and stuff
def parse_arguments():
    """Parse command-line arguments for the script."""
    parser = argparse.ArgumentParser(
        description="Convert APK files to images.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        '--config', default='config1.json', type=str, help='config file')
    parser.add_argument('--resume', '-r', action='store_true',
                        help='resume from checkpoint')
    args = parser.parse_args()

    with open(args.config) as config_file:
        config = json.load(config_file)
    config_dict = {
    'dataset': config['dataset'],
    'batch_size': config['batch_size'],
    'optimizer': config['optimizer'],
    'lr': config['lr'],
    'momentum': config['momentum'],
    'epochs': config['epochs'],
    'tb_path_test': config['tb_path_test'],
    'tb_path_train': config['tb_path_train'],
    'weight_decay': config['weight_decay'],
    'random_seed': config['random_seed'],
    'n_eval_step': config['n_eval_step'],
    'log_folder': config['log_folder'],
    'epsilon': config['epsilon'],
    'k': config['k'],
    'alpha': config['alpha'],
    'frac': config['frac']
    }

    return config_dict

#H - Function to load the dataset, returns train and test loaders
# I dont really understand what is the use of the mnist and cifar cases so they possibly won't stay
def loadDataset(config_dict, image_prec):
    if config_dict['dataset'] == 'MNIST':
        trainloader, testloader = mnist_loader(batch_size=config_dict['batch_size'])
        return trainloader, testloader
    elif config_dict['dataset'] == 'CIFAR':
        trainloader, testloader = cifar_loader(batch_size=config_dict['batch_size'])
        return trainloader, testloader
    elif config_dict['dataset'] == 'APK':
        trainloader, testloader = load_data_loaders(GOODWARE_FOLDER, MALWARE_FOLDER, load_fraction=image_prec)
        return trainloader, testloader
    
#H - This function will load the model, change the layers and put it on the device.
#Will return the pretrained model on the device, which is needed to create the adversarial attack.
#However he says "change the model to resnet18" and proceeds to put the resnet50... ?
def loadModelToDevice():
    # Change the model to ResNet-18
    model = models.resnet50(pretrained=True).to(device)

    # Change the fully connected layer structure to match ResNet-18's output (512 for ResNet-18 vs. 2048 for ResNet-50)
    model.fc = nn.Sequential(
                nn.Linear(2048, 500),
                nn.ReLU(inplace=True),  # Changed from Mish to ReLU; you can revert this if you have a specific reason to use Mish.
                nn.Linear(500, 2)).to(device)

    net = model.to(device)
    return net

#H - This function we create the optimizer depending the one we chose in the json
#However i dont yet know the differences between those optimizers so i wouldnt know how to chose
def defineOptimizer(net):
    if config_dict['optimizer'] == 0:
        optimizer = optim.SGD(
        net.parameters(), lr=config_dict['lr'],
        momentum=config_dict['momentum'], weight_decay=config_dict['weight_decay'])
        return optimizer
    elif config_dict['optimizer'] == 1:
        optimizer = optim.Adagrad(
        net.parameters(), lr=config_dict['lr'], weight_decay=config_dict['weight_decay'])
        return optimizer
    elif config_dict['optimizer'] == 2:
        optimizer = optim.Adam(net.parameters(), lr=config_dict['lr'], amsgrad=0, weight_decay=config_dict['weight_decay'])
        return optimizer

#H - Not sure what it is used for 
def createPath(config_dict):
    # Writer path for display on TensorBoard
    if not os.path.exists(config_dict['tb_path_test']):
        os.makedirs(config_dict['tb_path_test'])
    if not os.path.exists(config_dict['tb_path_test']):
        os.makedirs(config_dict['tb_path_test'])

    if not os.path.exists(config_dict['tb_path_test']):
        os.makedirs(config_dict['tb_path_test'])
    #path_name = config_tb_path + \
    #    str(config_experiment_number) + "_" + str(optimizer)

#H - This function will create the adversarial attack with the pretrained model and then train and save the new model
def adversarial_attack(net, config_dict):
    # Initialize weights
    net.apply(weights_init_uniform_rule)

    #load the model
    '''
    ckp_path = 'checkpoints/epoch_model_40.pth'
    checkpoint_model, start_epoch = load_ckp(ckp_path, net)
    '''
    attack = FastGradientSignUntargeted(net, 
                                            config_dict['epsilon'], 
                                            config_dict['alpha'], 
                                            min_val=0, 
                                            max_val=1, 
                                            max_iters=config_dict['k'], 
                                            _type='linf')    
    
    train(net,trainloader,testloader,adv_train=True,attack=attack)

    # Save the trained model
    torch.save(net, 'adv_trained_model_rgb_resnet_50.pth')

def save_images(original, adversarial, iteration, original_label=None, adversarial_label=None, save_path='/home/hugodhugo/recherche/Adversarial-Training-Pytorch/saved_image'):

    if not os.path.exists(save_path):
        os.makedirs(save_path)

    original = original.detach().permute(1, 2, 0).cpu().numpy()  # Change the shape to HxWxC
    adversarial = adversarial.detach().permute(1, 2, 0).cpu().numpy()  # Change the shape to HxWxC

    plt.figure(figsize=(10,5))
    
    plt.subplot(1, 2, 1)
    plt.imshow(original)
    plt.title(f"Original Image\nLabel: {original_label}" if original_label else "Original Image")
    
    plt.subplot(1, 2, 2)
    plt.imshow(adversarial)
    plt.title(f"Adversarial Image\nLabel: {adversarial_label}" if adversarial_label else "Adversarial Image")
    
    plt.savefig(os.path.join(save_path, f"image_{iteration}.png"), bbox_inches='tight')
    plt.close()




if __name__ == "__main__":
    config_dict = parse_arguments()

    torch.manual_seed(config_dict['random_seed'])
    if torch.cuda.is_available():
        torch.cuda.manual_seed(config_dict['random_seed'])

    image_prec = config_dict['frac']

    trainloader, testloader = loadDataset(config_dict, image_prec)

    net = loadModelToDevice()

    criterion = nn.CrossEntropyLoss()

    optimizer = defineOptimizer(net)

    createPath(config_dict)

    logger = create_logger(config_dict['epsilon'],config_dict['log_folder'],'train','info')

    adversarial_attack(net, config_dict)
