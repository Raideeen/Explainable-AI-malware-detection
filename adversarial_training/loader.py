import torch
import torchvision
import torchvision.transforms as transforms
import os
from tqdm import tqdm
import numpy as np
from PIL import Image
from torch.utils.data import Dataset, DataLoader
import torch
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split


def mnist_loader(batch_size):
    # Preprocess input
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.13, ), (0.3, ))])
    # Load   
    trainset = torchvision.datasets.MNIST(
        root='/home/hugodhugo', train=True, download=True, transform=transform)
    trainloader = torch.utils.data.DataLoader(
        trainset, batch_size=batch_size, shuffle=True, num_workers=2)
    testset = torchvision.datasets.MNIST(
        root='/home/hugodhugo', train=False, download=True, transform=transform)
    testloader = torch.utils.data.DataLoader(
        testset, batch_size=batch_size, shuffle=False, num_workers=2)
    return trainloader, testloader

def cifar_loader(batch_size):
    # Preprocess input
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4,fill=0, padding_mode='constant'),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor()
        
    ])

    transform_test = transforms.Compose(
        [transforms.ToTensor()])
    # Load
    trainset = torchvision.datasets.CIFAR10(root='/home/hugodhugo', train=True,
                                            download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=4)

    testset = torchvision.datasets.CIFAR10(root='/home/hugodhugo', train=False,
                                           download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                             shuffle=False, num_workers=4)
    return trainloader, testloader


# Define dataset class
class MyDataset(Dataset):
    def __init__(self, x, y, transform=None):
        self.x = x
        self.y = y
        self.transform = transform
        
    def __len__(self):
        return len(self.x)
    
    def __getitem__(self, index):
        img = Image.fromarray(self.x[index])
        label = self.y[index]
        
        if self.transform:
            img = self.transform(img)
            
        return img, label

def process_image(filepath, image_shape):
    image = Image.open(filepath)
    image_resized = image.resize(image_shape)
    image_array = np.array(image_resized)
    return image_array

def load_images(goodware_folder, malware_folder, image_shape=(256, 256), load_fraction=1.0):
    image_list = []
    labels = []

    # Load Goodware Images
    goodware_files = [f for f in os.listdir(goodware_folder) if f.endswith(".png") or f.endswith(".jpeg")]
    sample_goodware = np.random.choice(goodware_files, int(load_fraction * len(goodware_files)), replace=False)
    
    for filename in tqdm(sample_goodware, desc="Loading Goodware Images"):
        filepath = os.path.join(goodware_folder, filename)
        image_array = process_image(filepath, image_shape)
        image_list.append(image_array)
        labels.append(0)

    # Load Malware Images
    malware_files = [f for f in os.listdir(malware_folder) if f.endswith(".png") or f.endswith(".jpeg")]
    sample_malware = np.random.choice(malware_files, int(load_fraction * len(malware_files)), replace=False)
    
    for filename in tqdm(sample_malware, desc="Loading Malware Images"):
        filepath = os.path.join(malware_folder, filename)
        image_array = process_image(filepath, image_shape)
        image_list.append(image_array)
        labels.append(1 if "MALWARE" in filename else 0)

    images = np.array(image_list)
    labels = np.array(labels)

    return images, labels

# When you call the function, you can specify the fraction:
# Example: To load only 20% of the images
# x, y = load_images(goodware_folder_path, malware_folder_path, load_fraction=0.20)


def load_data_loaders(goodware_folder, malware_folder, load_fraction = 1.0):
    x, y = load_images(goodware_folder, malware_folder, image_shape=(256, 256), load_fraction = load_fraction)
    print('LEN X: ',len(x))
    print('LEN Y: ',len(y))

    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.20, random_state=42, shuffle=True)
    
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), normalize])

    train_dataset = MyDataset(x_train, y_train, transform)
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
    
    val_dataset = MyDataset(x_val, y_val, transform)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
    
    return train_loader, val_loader