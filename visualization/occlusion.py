import itertools
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from torch import nn, optim
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm


def process_image(filepath, image_shape):
    image = Image.open(filepath)
    image_resized = image.resize(image_shape)  # Resize the image
    image_array = np.array(image_resized)
    return image_array


def load_images(goodware_folder, malware_folder, image_shape=(256, 256)):
    image_list = []
    labels = []

    # Load Goodware images
    for filename in tqdm(os.listdir(goodware_folder), desc="Loading Goodware Images"):
        if filename.endswith(".png") or filename.endswith(".jpeg"):
            filepath = os.path.join(goodware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            labels.append(0)  # 0 for Goodware

    # Load Malware images
    for filename in tqdm(os.listdir(malware_folder), desc="Loading Malware Images"):
        if filename.endswith(".png") or filename.endswith(".jpeg"):
            filepath = os.path.join(malware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            if "MALWARE" in filename:
                labels.append(1)  # 1 for Malware
            else:
                labels.append(0)  # 0 for Goodware

    images = np.array(image_list)
    labels = np.array(labels)

    return images, labels


# Loading images
goodware_folder = "/home/sourav/Conti/train_data_rgb/Goodware_obf"
malware_folder = "/home/sourav/Conti/train_data_rgb/Malware_obf"
x, y = load_images(goodware_folder, malware_folder)

# Splitting into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(
    x, y, test_size=0.20, random_state=42, shuffle=True
)

# Plot and save a training image
# plt.imshow(x_train[96])
# plt.savefig('training_image.png')

# PyTorch device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Normalization and transformation
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])


# Define dataset class
class MyDataset(Dataset):
    def __init__(self, x, y, transform=None):
        self.x = x
        self.y = y
        self.transform = transform

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        img = Image.fromarray(self.x[index])
        label = self.y[index]

        if self.transform:
            img = self.transform(img)

        return img, label


transform = transforms.Compose(
    [transforms.Resize((224, 224)), transforms.ToTensor(), normalize]
)

# Training and validation
dataset = MyDataset(x_train, y_train, transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)


criterion = nn.CrossEntropyLoss()
# optimizer = optim.Adam(model.fc.parameters())


# 1. Load the trained model
model = torch.load("trained_model_rgb.pth")
model.eval()
model.to(device)

# Validation
val_dataset = MyDataset(x_val, y_val, transform)
val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)


def occlude_image(img, occluder_size, x, y):
    """Returns an image with an occlusion patch applied at specified location.
    Parameters:
    - img: torch Tensor of shape (C, H, W)
    - occluder_size: tuple (height, width) specifying the size of the occlusion patch
    - x, y: top-left coordinates where the occlusion patch should be applied
    """
    occluded_img = img.clone()
    occluded_img[
        :, y : y + occluder_size[1], x : x + occluder_size[0]
    ] = 0  # setting the patch to black; can be changed to other values
    return occluded_img


def compute_occlusion_sensitivity(model, img, true_label, occluder_size=(50, 50)):
    """
    Compute the change in model prediction when applying an occlusion patch to the image.
    Parameters:
    - model: a pretrained CNN
    - img: torch Tensor of shape (1, C, H, W)
    - true_label: the true label of the image
    - occluder_size: tuple (height, width) specifying the size of the occlusion patch
    Returns:
    - sensitivity_map: a torch Tensor of shape (H, W) containing the change in model prediction
    """
    _, _, H, W = img.shape
    sensitivity_map = torch.zeros((H, W))

    original_output = model(img)
    original_prob = torch.nn.functional.softmax(original_output, dim=1)
    original_confidence = original_prob[0, true_label].item()

    for y in range(0, H - occluder_size[1] + 1):
        for x in range(0, W - occluder_size[0] + 1):
            occluded_img = (
                occlude_image(img[0], occluder_size, x, y).unsqueeze(0).to(device)
            )
            occluded_output = model(occluded_img)
            occluded_prob = torch.nn.functional.softmax(occluded_output, dim=1)
            occluded_confidence = occluded_prob[0, true_label].item()

            drop_in_confidence = original_confidence - occluded_confidence
            sensitivity_map[y, x] = drop_in_confidence

    return sensitivity_map


# Choose an image from the validation set
img_idx = 5
X_tensor = val_dataset[img_idx][0].unsqueeze(0).to(device)
y_tensor = val_dataset[img_idx][1]

sensitivity_map = compute_occlusion_sensitivity(model, X_tensor, y_tensor)

# Visualize the sensitivity map
plt.figure(figsize=(10, 10))  # you can adjust the figure size as needed
plt.imshow(sensitivity_map.cpu(), cmap="hot")
plt.colorbar()
plt.title("Occlusion Sensitivity Map")

# Save the image
output_path = "occlusion_sensitivity_map.png"
plt.savefig(output_path, bbox_inches="tight")

# If you want to see the image in the notebook/interface as well:
plt.show()

print(f"Sensitivity map saved to {output_path}")

# 1. Create a new folder for saving the sensitivity maps
output_folder = "occlusion_sensitivity_maps"
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# Create sub-folders for Goodware and Malware
goodware_folder = os.path.join(output_folder, "Goodware")
malware_folder = os.path.join(output_folder, "Malware")
if not os.path.exists(goodware_folder):
    os.makedirs(goodware_folder)
if not os.path.exists(malware_folder):
    os.makedirs(malware_folder)


def generate_and_save_images(img_idx, class_name):
    """Generate and save the sensitivity map and the original image for a given image index."""
    X_tensor = val_dataset[img_idx][0].unsqueeze(0).to(device)
    y_tensor = val_dataset[img_idx][1]

    sensitivity_map = compute_occlusion_sensitivity(model, X_tensor, y_tensor)

    # Visualize and save the sensitivity map
    plt.figure(figsize=(10, 10))
    plt.imshow(sensitivity_map.cpu(), cmap="hot")
    plt.colorbar()
    plt.title(f"Occlusion Sensitivity Map for {class_name} Image Index {img_idx}")
    sensitivity_output_path = os.path.join(
        output_folder, class_name, f"{class_name}_{img_idx}_sensitivity.png"
    )
    plt.savefig(sensitivity_output_path, bbox_inches="tight")
    plt.close()  # Close the figure

    # Save the original image
    original_image = (
        val_dataset[img_idx][0].numpy().transpose((1, 2, 0))
    )  # Convert C,H,W -> H,W,C
    # You need to reverse the normalization for displaying the original image.
    # Assuming mean and std lists are defined earlier in your code.
    original_image = original_image * np.array([0.229, 0.224, 0.225]) + np.array(
        [0.485, 0.456, 0.406]
    )
    plt.figure(figsize=(10, 10))
    plt.imshow(original_image)
    plt.title(f"Original {class_name} Image Index {img_idx}")
    original_output_path = os.path.join(
        output_folder, class_name, f"{class_name}_{img_idx}_original.png"
    )
    plt.savefig(original_output_path, bbox_inches="tight")
    plt.close()  # Close the figure

    return sensitivity_output_path, original_output_path


# 2. Filter the validation set for Malware and Goodware images
goodware_indices = [i for i, label in enumerate(y_val) if label == 0]
malware_indices = [i for i, label in enumerate(y_val) if label == 1]

# Generate and save images:
for idx in goodware_indices[:50]:  # First 50 Goodware images
    sens_path, orig_path = generate_and_save_images(idx, "Goodware")
    print(f"Sensitivity map saved to {sens_path}")
    print(f"Original image saved to {orig_path}")

for idx in malware_indices[:50]:  # First 50 Malware images
    sens_path, orig_path = generate_and_save_images(idx, "Malware")
    print(f"Sensitivity map saved to {sens_path}")
    print(f"Original image saved to {orig_path}")
