import argparse
import itertools
import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from torch import nn, optim
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

# Make the script interactive through the CLI
parser = argparse.ArgumentParser(
    description="Script to convert APK files to images.",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)

# Add the type of images the APK files should be converted to
parser.add_argument(
    "-t",
    "--type",
    choices=["RGB", "BW"],
    required=True,
    help="Type of images.",
)

# Add the padding type to use
parser.add_argument(
    "-p",
    "--padding_type",
    choices=["random", "black", "white"],
    required=True,
    help="Type of padding to use.",
)

# Add location to the root location of the images to be saved at
parser.add_argument(
    "-i",
    "--images",
    nargs="?",
    default="_images",
    help="Provide the root path of the images to be saved at. It is a path relative to your current working directory.",
)

# Add choice on the location of the saliency maps to be saved at
parser.add_argument(
    "-s",
    "--saliency_maps",
    nargs="?",
    default="visualization/_saliency_maps",
    help="Provide the root path of the saliency maps to be saved at. It is a path relative to your current working directory.",
)

# Add location of where the model is saved
parser.add_argument(
    "-m",
    "--model_location",
    nargs="?",
    default="model_training/_models",
    help="Provide the root path of the models location. It is a path. It is a path relative to your current working directory.",
)

# Add choice on which type of device to run the script
parser.add_argument(
    "-r", "--run_on", choices=["local", "cluster"], nargs="?", default="cluster"
)


args = parser.parse_args()


# 1
def process_image(filepath, image_shape):
    image = Image.open(filepath)
    image_resized = image.resize(image_shape)  # Resize the image
    image_array = np.array(image_resized)
    return image_array


# 2
def load_images(goodware_folder, malware_folder, image_shape=(256, 256)):
    image_list = []
    labels = []

    # Load Goodware images
    for filename in tqdm(os.listdir(goodware_folder), desc="Loading Goodware Images"):
        if filename.endswith(".png") or filename.endswith(".jpg"):
            filepath = os.path.join(goodware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            labels.append(0)  # 0 for Goodware

    # Load Malware images
    for filename in tqdm(os.listdir(malware_folder), desc="Loading Malware Images"):
        if filename.endswith(".png") or filename.endswith(".jpg"):
            filepath = os.path.join(malware_folder, filename)
            image_array = process_image(filepath, image_shape)
            image_list.append(image_array)
            if "MALWARE" in filename:
                labels.append(1)  # 1 for Malware
            else:
                labels.append(0)  # 0 for Goodware

    images = np.array(image_list)
    labels = np.array(labels)

    return images, labels


# Loading images
goodware_folder, malware_folder = "", ""

# Loading images
match args.run_on:
    case "local":
        goodware_folder = (
            args.images
            + "/Subset_goodware_obf"
            + f"_{args.type}_{args.padding_type}_padding"
        )
        malware_folder = (
            args.images
            + "/Subset_malware_obf"
            + f"_{args.type}_{args.padding_type}_padding"
        )
    case "cluster":
        goodware_folder = (
            args.images + "/Goodware_obf" + f"_{args.type}_{args.padding_type}_padding"
        )
        malware_folder = (
            args.images + "/Malware_obf" + f"_{args.type}_{args.padding_type}_padding"
        )

x, y = load_images(goodware_folder, malware_folder)

# Splitting into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(
    x, y, test_size=0.20, random_state=42, shuffle=True
)

# Constant for number of images
N = x.shape[0]

# Plot and save a training image
# plt.imshow(x_train[96])
# plt.savefig('training_image.png')

# PyTorch device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Normalization and transformation
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])


# Define dataset class
class MyDataset(Dataset):
    def __init__(self, x, y, transform=None):
        self.x = x
        self.y = y
        self.transform = transform

    def __len__(self):
        return len(self.x)

    def __getitem__(self, index):
        img = Image.fromarray(self.x[index])
        label = self.y[index]

        if self.transform:
            img = self.transform(img)

        return img, label


transform = transforms.Compose(
    [transforms.Resize((224, 224)), transforms.ToTensor(), normalize]
)

# Training and validation
dataset = MyDataset(x_train, y_train, transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)


criterion = nn.CrossEntropyLoss()
# optimizer = optim.Adam(model.fc.parameters())


# 1. Load the trained model

model = torch.load(
    args.model_location
    + f"/trained_model_resnet_18_{args.type}_{args.padding_type}_padding.pth"
)
model.eval()
model.to(device)


# 2. Implement function to compute saliency
def compute_saliency_maps(X, y, model):
    """
    Compute a class saliency map using the model for images X and labels y.
    Input:
    - X: Input images; torch Tensor of shape (N, 3, H, W)
    - y: Labels for X; torch LongTensor of shape (N,)
    - model: A pretrained CNN that will be used to compute the saliency map.
    Returns:
    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input images.
    """
    model.eval()
    X.requires_grad_()
    scores = model(X)
    loss = criterion(scores, y)
    loss.backward()
    saliency, _ = X.grad.data.abs().max(dim=1)
    return saliency


# Validation
val_dataset = MyDataset(x_val, y_val, transform)
val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)
# 3. Choose an image from the validation set
img_idx = 5
X_tensor = val_dataset[img_idx][0].unsqueeze(0).to(device)
y_tensor = torch.tensor([val_dataset[img_idx][1]]).to(device)

# 4. Compute saliency
saliency = compute_saliency_maps(X_tensor, y_tensor, model)

# Ensure necessary directories exist
save_directory = (
    f"{args.saliency_maps}/saliency_maps_18_{args.type}_{args.padding_type}_padding"
)
malware_dir = os.path.join(
    save_directory, f"Malwares_18_{args.type}_{args.padding_type}_padding"
)
goodware_dir = os.path.join(
    save_directory, f"Goodwares_18_{args.type}_{args.padding_type}_padding"
)

if not os.path.exists(save_directory):
    os.makedirs(save_directory)
    os.makedirs(malware_dir)
    os.makedirs(goodware_dir)


def save_image_and_saliency(img_idx, dataloader, folder):
    X_tensor, y_tensor = dataloader.dataset[img_idx]
    X_tensor = X_tensor.unsqueeze(0).to(device)
    y_tensor = torch.tensor([y_tensor]).to(device)

    # Compute saliency
    saliency = compute_saliency_maps(X_tensor, y_tensor, model)

    # Save original image
    original_img_path = os.path.join(folder, f"Original_{img_idx}.png")
    plt.imshow(X_tensor[0].permute(1, 2, 0).cpu().detach().numpy())
    plt.axis("off")
    plt.savefig(original_img_path)
    plt.close()

    # Save saliency map
    saliency_img_path = os.path.join(folder, f"Saliency_{img_idx}.png")
    plt.imshow(saliency[0].cpu(), cmap=plt.cm.hot)
    plt.colorbar()
    plt.axis("off")
    plt.savefig(saliency_img_path)
    plt.close()


# Limiting the loop to 100 images, and ensuring both classes are covered
goodware_count = 0
malware_count = 0
for img_idx in range(len(val_dataloader.dataset)):
    label = val_dataloader.dataset[img_idx][1]

    if label == 0 and goodware_count < N:  # Goodware
        save_image_and_saliency(img_idx, val_dataloader, goodware_dir)
        goodware_count += 1
    elif label == 1 and malware_count < N:  # Malware
        save_image_and_saliency(img_idx, val_dataloader, malware_dir)
        malware_count += 1

    if goodware_count >= N and malware_count >= N:
        break


# Initialize sum arrays for feature importance maps
combined_saliency_malware = torch.zeros_like(saliency[0].cpu())
combined_saliency_goodware = torch.zeros_like(saliency[0].cpu())


def compute_and_aggregate_saliency(img_idx, dataloader, combined_array):
    X_tensor, y_tensor = dataloader.dataset[img_idx]
    X_tensor = X_tensor.unsqueeze(0).to(device)
    y_tensor = torch.tensor([y_tensor]).to(device)

    # Compute saliency
    saliency = compute_saliency_maps(X_tensor, y_tensor, model)

    # Aggregate
    combined_array += saliency[0].cpu()

    return combined_array


# Limiting the loop to 100 images, and ensuring both classes are covered
goodware_count = 0
malware_count = 0
for img_idx in range(len(val_dataloader.dataset)):
    label = val_dataloader.dataset[img_idx][1]

    if label == 0 and goodware_count < N:  # Goodware
        combined_saliency_goodware = compute_and_aggregate_saliency(
            img_idx, val_dataloader, combined_saliency_goodware
        )
        goodware_count += 1
    elif label == 1 and malware_count < N:  # Malware
        combined_saliency_malware = compute_and_aggregate_saliency(
            img_idx, val_dataloader, combined_saliency_malware
        )
        malware_count += 1

    if goodware_count >= N and malware_count >= N:
        break

# Average the combined saliency maps
avg_saliency_goodware = combined_saliency_goodware / N
avg_saliency_malware = combined_saliency_malware / N

# Visualize the combined feature importance maps
plt.figure(figsize=(10, 5))

# For Goodware
plt.subplot(1, 2, 1)
plt.imshow(avg_saliency_goodware, cmap=plt.cm.hot)
plt.colorbar()
plt.title("Average Saliency Map for Goodware")

# For Malware
plt.subplot(1, 2, 2)
plt.imshow(avg_saliency_malware, cmap=plt.cm.hot)
plt.colorbar()
plt.title("Average Saliency Map for Malware")

plt.tight_layout()
plt.show()

# Save the combined feature importance maps if needed
plt.imsave(
    os.path.join(goodware_dir, "Average_Saliency_Goodware.png"),
    avg_saliency_goodware,
    cmap=plt.cm.hot,
)
plt.imsave(
    os.path.join(malware_dir, "Average_Saliency_Malware.png"),
    avg_saliency_malware,
    cmap=plt.cm.hot,
)
